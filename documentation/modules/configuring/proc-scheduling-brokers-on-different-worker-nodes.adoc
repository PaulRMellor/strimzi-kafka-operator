// Module included in the following assemblies:
//
// assembly-scheduling.adoc

[id='proc-scheduling-brokers-on-different-worker-nodes-{context}']
= Configuring pod anti-affinity for Kafka nodes

[role="_abstract"]
By default, multiple Kafka nodes from the same pool can run on the same worker node in your Kubernetes cluster.
If that worker node fails, all Kafka nodes hosted on it become unavailable, impacting the reliability of your cluster.

To improve fault tolerance, configure `podAntiAffinity` in your `KafkaNodePool` resource so that Kafka nodes within a pool are scheduled on different worker nodes. 

.Prerequisites

* A Kubernetes cluster
* A running Cluster Operator
* Other workloads in the cluster are labelled

.Procedure

. In your `KafkaNodePool` custom resource, edit the `affinity` property in the `spec.template.pod` section.
+
To prevent Kafka pods from the same node pool from sharing a worker node, add a `podAntiAffinity` rule.
+
* Use a `labelSelector` to identify the pods using the node pool name.
* Set the `topologyKey` to `"kubernetes.io/hostname"`. 
This defines each worker node as a separate domain for the scheduling rule, preventing the targeted pods from being placed on the same host.
+
.Example anti-affinity configuration for a node pool
[source,yaml,subs="+quotes,attributes+"]
----
apiVersion: {KafkaNodePoolApiVersion}
kind: KafkaNodePool
metadata:
  name: broker
  labels:
    strimzi.io/cluster: my-cluster
spec:
  replicas: 3
  roles:
    - broker
  template:
    pod:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: strimzi.io/pool-name
                    operator: In
                    values:
                      - broker
              topologyKey: "kubernetes.io/hostname"
  # ...
----
+
NOTE: For a stricter, cluster-wide anti-affinity rule, use the `strimzi.io/cluster` label with your cluster name as the value. 
This prevents a pod from running on the same node as any other pod from the same Kafka cluster (such as controllers or brokers from a different pool).

. Apply the changes to the `KafkaNodePool` configuration.
