// Module included in the following assemblies:
//
// configuring/assembly-scaling-clusters.adoc

[id='proc-generating-reassignment-json-files-{context}']
= Generating reassignment JSON files

[role="_abstract"]
This procedure describes how to generate a reassignment JSON file.
Use the reassignment file with the `kafka-reassign-partitions.sh` tool to reassign partitions after scaling a Kafka cluster.

The steps describe a secure reassignment process that uses mTLS.
You'll need a Kafka cluster that uses TLS encryption and mTLS authentication.

You'll need the following to establish a connection:

* The cluster CA certificate generated by the Cluster Operator when the Kafka cluster is created.
* The user CA certificate and private key generated by the User Operator when a user is created for client access to the Kafka cluster

In this procedure, the CA certificates and public key are extracted from the cluster and user secrets that contain them in PEM (`.crt` and `.key`) format.

.Prerequisites

* You have a running Cluster Operator.
* You have a running Kafka cluster based on a `Kafka` resource configured with internal TLS encryption and mTLS authentication.
+
.Kafka configuration with TLS encryption and mTLS authentication
[source,yaml,subs="attributes+"]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    listeners:
      # ...
      - name: tls
        port: 9093
        type: internal
        tls: true <1>
        authentication:
          type: tls <2>
    # ...
----
<1> Enables TLS encryption for the internal listener.
<2> Listener authentication mechanism xref:assembly-securing-kafka-brokers-str[specified as mutual `tls`].
* The running Kafka cluster contains a set of topics and partitions to reassign.
+
.Example topic configuration for `my-topic`
[source,yaml,subs="attributes+"]
----
apiVersion: {KafkaTopicApiVersion}
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 10
  replicas: 3
  config:
    retention.ms: 7200000
    segment.bytes: 1073741824
    # ...
----
* You have a `KafkaUser` configured with ACL rules that specify permission to produce and consume topics from the Kafka brokers.
+
--
.Example Kafka user configuration with ACL rules to allow operations on `my-topic` and `my-cluster`
[source,yaml,subs="attributes+"]
----
apiVersion: {KafkaUserApiVersion}
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication: <1>
    type: tls
  authorization:
    type: simple <2>
    acls:
      # access to the topic
      - resource:
          type: topic
          name: my-topic
        operations:
          - Create
          - Describe
          - Read
          - AlterConfigs
        host: "*"
      # access to the cluster
      - resource:
          type: cluster
        operations:
          - Alter
          - AlterConfigs
        host: "*"
      # ...
  # ...
----
<1> User authentication mechanism defined as mutual `tls`.
<2> Simple authorization and accompanying list of ACL rules.
--

.Procedure

. Extract the cluster CA certificate from the `_<cluster_name>_-cluster-ca-cert` secret of the Kafka cluster.
+
[source,shell,subs="+quotes"]
kubectl get secret _<cluster_name>_-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d > ca.crt
+
Replace _<cluster_name>_ with the name of the Kafka cluster.
When you deploy Kafka using the `Kafka` resource, a secret with the cluster CA certificate is created with the Kafka cluster name (`_<cluster_name>_-cluster-ca-cert`).
For example, `my-cluster-cluster-ca-cert`.

. Run a new interactive pod container using the Strimzi Kafka image to connect to a running Kafka broker.
+
[source,shell,subs="+quotes,attributes"]
----
kubectl run --restart=Never --image={DockerKafkaImageCurrent} _<interactive_pod_name>_ -- /bin/sh -c "sleep 3600"
----
+
Replace _<interactive_pod_name>_ with the name of the pod.

. Copy the cluster CA certificate to the interactive pod container.
+
[source,shell,subs=+quotes]
kubectl cp ca.crt _<interactive_pod_name>_:/tmp

. Extract the user CA certificate from the `_<user_name>_` secret of the Kafka user that has permission to access the Kafka brokers.
+
[source,shell,subs="+quotes"]
kubectl get secret _<user_name>_ -o jsonpath='{.data.user\.crt}' | base64 -d > user.crt
+
Replace _<kafka_user>_ with the name of the Kafka user.
When you create a Kafka user using the `KafkaUser` resource, a secret with the user CA certificate is created with the Kafka user name.
For example, `my-user`.

. Extract the private key of the user from the `_<user_name>_` secret.
+
[source,shell,subs="+quotes"]
kubectl get secret _<user_name>_ -o jsonpath='{.data.user\.key}' | base64 -d > user.key
+
The CA certificates (public keys) and private key allow the interactive pod container to connect to the Kafka broker. 

. Create a `config.properties` file.
+
Add the certificates and private user key you extracted in the previous steps.
+
* Add the truststore credentials to identify and authenticate with the Kafka cluster.
* Add the keystore credentials to verify the user when connecting to the Kafka cluster.
+
.Configuration file with credentials
[source,properties,subs="+quotes,attributes"]
----
bootstrap.servers=__<kafka_cluster_name>__-kafka-bootstrap:9093 # <1>
security.protocol=SSL # <2>
ssl.truststore.type=PEM # <3>
ssl.truststore.location=/tmp/ca.crt # <4>
ssl.keystore.certificate.chain=-----BEGIN CERTIFICATE----- \n__<user_certificate_content_line_1>__\n__<user_certificate_content_line_n>__\n-----END CERTIFICATE----- # <5>
ssl.keystore.key=----BEGIN PRIVATE KEY-----\n__<user_key_content_line_1>__\n__<user_key_content_line_n>__\n-----END PRIVATE KEY----- # <6>
----
<1> The bootstrap server address to connect to the Kafka cluster. Use your own Kafka cluster name to replace _<kafka_cluster_name>_.
<2> The security protocol option when using TLS for encryption.
<3> PEM file format of the truststore (and keystore). 
<4> The truststore location contains the public key certificate (`ca.crt`) for the Kafka cluster.
<5> The user certificate of the Kafka user.  
<6> The private key of the Kafka user.

NOTE: Add the keystore certificate and the private key directly to the configuration.
Add as a single-line format. 
Start the certificate and key with an escape sequence (`\n`). 
End each line from the original certificate with a `\n`.

. Copy the `config.properties` file to the interactive pod container.
+
[source,shell,subs=+quotes]
kubectl cp config.properties _<interactive_pod_name>_:/tmp/config.properties

. Prepare a JSON file named `topics.json` that specifies the topics to move.
+
--
Specify topic names as a comma-separated list.

.Example JSON file to reassign all the partitions of `topic-a` and `topic-b`
[source,json]
----
{
  "version": 1,
  "topics": [
    { "topic": "topic-a"},
    { "topic": "topic-b"}
  ]
}
----
--

. Copy the `_topics.json_` file to the interactive pod container.
+
[source,shell,subs=+quotes]
kubectl cp topics.json _<interactive_pod_name>_:/tmp/topics.json

. Start a shell process in the interactive pod container.
+
[source,shell,subs=+quotes]
kubectl exec -n _<namespace>_ -ti _<interactive_pod_name>_ /bin/bash
+
Replace _<namespace>_ with the Kubernetes namespace where the pod is running.

. Use the `kafka-reassign-partitions.sh` command to generate the reassignment JSON.
+
.Example command to move all the partitions of `topic-a` and `topic-b` to brokers `0`, `1` and `2`
[source,shell,subs=+quotes]
----
bin/kafka-reassign-partitions.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 \
  --command-config /tmp/config.properties \
  --topics-to-move-json-file /tmp/topics.json \
  --broker-list 0,1,2 \
  --generate
----

[role="_additional-resources"]
.Additional resources

* xref:proc-config-kafka-{context}[]
* xref:proc-configuring-kafka-topic-{context}[]
* xref:proc-configuring-kafka-user-{context}[]
