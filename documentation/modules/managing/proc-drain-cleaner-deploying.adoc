// This assembly is included in the following assemblies:
//
// assembly-drain-cleaner.adoc

[id='proc-drain-cleaner-deploying-{context}']
= Deploying the Strimzi Drain Cleaner using installation files

[role="_abstract"] 
Deploy the Strimzi Drain Cleaner to the Kubernetes cluster where the Cluster Operator and Kafka cluster are running.

.Prerequisites

* You have xref:drain-cleaner-prereqs-str[downloaded the Strimzi Drain Cleaner deployment files].
* You have a highly available Kafka cluster deployment running with Kubernetes worker nodes that you would like to update.
* Topics are replicated for high availability.
+
Topic configuration specifies a replication factor of at least 3 and a minimum number of in-sync replicas to 1 less than the replication factor.
+
.Kafka topic replicated for high availability
[source,yaml,subs="attributes+"]
----
apiVersion: {KafkaTopicApiVersion}
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 1
  replicas: 3
  config:
    # ...
    min.insync.replicas: 2
    # ...
----

.Excluding Kafka or ZooKeeper

If you don't want to include Kafka or ZooKeeper pods in Drain Cleaner operations, change the default environment variables in the Drain Cleaner `Deployment` configuration file.

* Set `STRIMZI_DRAIN_KAFKA` to `false` to exclude Kafka pods
* Set `STRIMZI_DRAIN_ZOOKEEPER` to `false` to exclude ZooKeeper pods

.Example configuration to exclude ZooKeeper pods
[source,yaml,subs="attributes+"]
----
apiVersion: apps/v1
kind: Deployment
spec:
  # ...
  template:
    spec:
      serviceAccountName: strimzi-drain-cleaner
      containers:
        - name: strimzi-drain-cleaner
          # ...
          env:
            - name: STRIMZI_DRAIN_KAFKA
              value: "true"
            - name: STRIMZI_DRAIN_ZOOKEEPER
              value: "false"
          # ...
----

.Procedure

. Configure a pod disruption budget of `0` (zero) for your Kafka deployment using `template` settings in the `Kafka` resource.
+
.Specifying a pod disruption budget
[source,yaml,subs=attributes+]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
  namespace: myproject
spec:
  kafka:
    template:
      podDisruptionBudget:
        maxUnavailable: 0

  # ...
  zookeeper:
    template:
      podDisruptionBudget:
        maxUnavailable: 0
  # ...
----
+
Reducing the maximum pod disruption budget to zero prevents Kubernetes from automatically evicting the pods in case of voluntary disruptions,
leaving the Strimzi Drain Cleaner and Strimzi Cluster Operator to roll the pod which will be scheduled by Kubernetes on a different worker node.
+
Add the same configuration for ZooKeeper if you want to use Strimzi Drain Cleaner to drain ZooKeeper nodes.

. Update the `Kafka` resource:
+
[source,shell,subs=+quotes]
kubectl apply -f <kafka_configuration_file>

. Deploy the Strimzi Drain Cleaner.
+
--
ifdef::Section[]
* If you are using `cert-manager` with Kubernetes, apply the resources in the `/install/drain-cleaner/certmanager` directory.
+
[source,shell,subs="attributes+"]
----
kubectl apply -f ./install/drain-cleaner/certmanager
----
+
The TLS certificates for the webhook are generated automatically and injected into the webhook configuration.
+
* If you are not using `cert-manager` with Kubernetes, do the following:
+
.. xref:proc-drain-cleaner-certs-{context}[Add TLS certificates to use in the deployment].
+
Any certificates you add must be renewed before they expire. 
+
.. Apply the resources in the `/install/drain-cleaner/kubernetes` directory.
+
[source,shell,subs="attributes+"]
----
kubectl apply -f ./install/drain-cleaner/kubernetes
----
endif::Section[]
--
+
* To run the Drain Cleaner on OpenShift, apply the resources in the `/install/drain-cleaner/openshift` directory.
+
[source,shell,subs="attributes+"]
----
kubectl apply -f ./install/drain-cleaner/openshift
----
