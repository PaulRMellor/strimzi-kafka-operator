// Module included in the following assemblies:
//
// deploying/assembly_deploy-kafka-connect.adoc

[id='assembly-creating-managing-connectors-{context}']

[role="_abstract"]
= Creating and managing connectors

When you have created a container image for your connector plug-in, you need to create a connector instance in your Kafka Connect cluster.
You can then configure, monitor, and manage a running connector instance.

A connector is an instance of a particular _connector class_ that knows how to communicate with the relevant external system in terms of messages.
Connectors are available for many external systems, or you can create your own.

You can create _source_ and _sink_ types of connector.

Source connector:: A source connector is a runtime entity that fetches data from an external system and feeds it to Kafka as messages.
Sink connector:: A sink connector is a runtime entity that fetches messages from Kafka topics and feeds them to an external system.

Strimzi provides two APIs for creating and managing connectors:

* `KafkaConnector` resources (referred to as KafkaConnectors)
* Kafka Connect REST API

Using the APIs, you can:

* Check the status of a connector instance
* Reconfigure a running connector
* Increase or decrease the number of connector tasks for a connector instance
* Restart connectors
* Restart connector tasks, including failed tasks
* Pause a connector instance
* Resume a previously paused connector instance
* Delete a connector instance

== KafkaConnector resources

KafkaConnectors allow you to create and manage connector instances for Kafka Connect in a Kubernetes-native way, so an HTTP client such as cURL is not required.
Like other Kafka resources, you declare a connectorâ€™s desired state in a `KafkaConnector` YAML file that is deployed to your Kubernetes cluster to create the connector instance.
`KafkaConnector` resources must be deployed to the same namespace as the Kafka Connect cluster they link to.

You manage a running connector instance by updating its corresponding `KafkaConnector` resource, and then applying the updates.
You remove a connector by deleting its corresponding `KafkaConnector`.

To ensure compatibility with earlier versions of Strimzi, KafkaConnectors are disabled by default. To enable them for a Kafka Connect cluster, you must use annotations on the `KafkaConnect` resource.
For instructions, see link:{BookURLUsing}#proc-kafka-connect-config-str[Configuring Kafka Connect^].

When KafkaConnectors are enabled, the Cluster Operator begins to watch for them. It updates the configurations of running connector instances to match the configurations defined in their KafkaConnectors.

Strimzi provides xref:deploy-examples-{context}[example configuration files], including the following example `KafkaConnector` file:

* `examples/connect/source-connector.yaml`.

You can use this example to create and manage a `FileStreamSourceConnector` and a `FileStreamSinkConnector`, as described in xref:proc-deploying-kafkaconnector-{context}[Deploying the example `KafkaConnector` resources].

NOTE: You can xref:proc-manual-restart-connector-str[restart a connector] or xref:proc-manual-restart-connector-task-str[restart a connector task] by annotating a `KafkaConnector` resource.

//Procedure to deploy a KafkaConnector resource
include::modules/proc-deploying-kafkaconnector.adoc[leveloffset=+1]
//Procedure to restart a Kafka connector
include::modules/proc-manual-restart-connector.adoc[leveloffset=+1]
//Procedure to restart a Kafka connector task
include::modules/proc-manual-restart-connector-task.adoc[leveloffset=+1]
//Tips to expose the Kafka Connect API
include::modules/con-exposing-kafka-connect-api.adoc[leveloffset=+1]
